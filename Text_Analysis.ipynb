{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Cleaning\n",
    "Feature Engineering + Text Cleaning. Outputs three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jasper\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Setup\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import spacy.cli\n",
    "import matplotlib.pyplot as plt\n",
    "import pdtext\n",
    "import readability\n",
    "from pdtext.tf import word_count\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load dataset\n",
    "try:\n",
    "    df = pd.read_csv('df_final.csv')\n",
    "except:\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile('df_final.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('')\n",
    "    df = pd.read_csv('df_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove missing text and clean text for LDA\n",
    "# much of the text is missing; thus, we keep only the data with text\n",
    "missing = (df[\"text\"].isnull()) | ((df[\"text\"] == '[deleted]')) | ((df[\"text\"] == '[removed]'))\n",
    "df = df.loc[~missing]\n",
    "\n",
    "##############################\n",
    "# clean the text in df for LDA\n",
    "##############################\n",
    "# stemming\n",
    "eng_stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def stem_sentence(sentence):\n",
    "    new_sentence = ''\n",
    "    for word in word_tokenize(sentence):\n",
    "        new_sentence = new_sentence + ' ' + eng_stemmer.stem(word)\n",
    "    return new_sentence.strip()\n",
    "\n",
    "def clean_text(s, stem = True):\n",
    "    # lowercase\n",
    "    s = s.lower()\n",
    "    # remove numbers: https://stackoverflow.com/questions/12851791/removing-numbers-from-string\n",
    "    s = ''.join([i for i in s if not i.isdigit()])\n",
    "    # remove punctuation:\n",
    "    s = s.translate(str.maketrans('', '', string.punctuation))\n",
    "    # stem\n",
    "    if stem:\n",
    "        s = stem_sentence(s)\n",
    "    return(s)\n",
    "\n",
    "# get clean text from which to extract topics\n",
    "clean_text_df = df['text'].apply(clean_text)\n",
    "\n",
    "clean_text_df = pd.DataFrame(clean_text_df, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check\n",
    "clean_text_df.shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Export clean_text_df to csv\n",
    "clean_text_df.to_csv('nlp_data/clean_text_df.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Sentiment\n",
    "# For background/more info, check out: \n",
    "# https://github.com/cjhutto/vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "fn_analyzer = lambda x: analyzer.polarity_scores(x)['compound']\n",
    "\n",
    "# # example for paper\n",
    "# analyzer.polarity_scores(example_text)['compound'] # 0.7579\n",
    "\n",
    "# warning --slow\n",
    "sentiment = df['text'].apply(fn_analyzer)\n",
    "\n",
    "sentiment.head()\n",
    "\n",
    "# export sentiment\n",
    "sentiment.to_csv('nlp_data/sentiment.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Feature Engineering\n",
    "# features we can get from the readability package\n",
    "features = ['dale_chall', 'characters_per_word', 'syll_per_word', 'words_per_sentence', 'sentences_per_paragraph',\n",
    "            'type_token_ratio', 'characters', 'syllables',\n",
    "            'words', 'wordtypes', 'sentences', 'paragraphs',\n",
    "            'long_words', 'complex_words', 'complex_words_dc',\n",
    "            'tobeverb', 'auxverb', 'conjunction', 'pronoun',\n",
    "            'preposition', 'nominalization']\n",
    "\n",
    "# initiate empty features dataframe\n",
    "feature_df = pd.DataFrame(np.nan, index = range(len(df)),\n",
    "                          columns=features)\n",
    "\n",
    "# function that outputs a row of features\n",
    "def get_features(text, idx):\n",
    "    results = readability.getmeasures(text, lang='en')\n",
    "    DaleChall = pd.DataFrame(results['readability grades']['DaleChallIndex'],\n",
    "                             columns = ['dale_chall'],\n",
    "                             index = [idx])\n",
    "    sentence_df = pd.DataFrame(results['sentence info'],\n",
    "                               columns = results['sentence info'].keys(),\n",
    "                               index = [idx])\n",
    "    word_df = pd.DataFrame(results['word usage'],\n",
    "                               columns = results['word usage'].keys(),\n",
    "                               index = [idx])\n",
    "    op = pd.concat([DaleChall, sentence_df, word_df], axis=1)\n",
    "    return(op)\n",
    "\n",
    "# # example\n",
    "# get_features(example_text, idx=0)\n",
    "\n",
    "# fills the feature dataframe warning --slow\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        op = get_features(df['text'].iloc[i], idx=i)\n",
    "    except:\n",
    "        op = pd.DataFrame(np.nan, index = [i],columns=features)\n",
    "    feature_df.append(op)\n",
    "\n",
    "# add the index and id\n",
    "# we need this to join the dataframes later on\n",
    "\n",
    "feature_df.index = df.index\n",
    "feature_df['id'] = df['id']\n",
    "\n",
    "##########################\n",
    "# export feature_df as csv\n",
    "##########################\n",
    "feature_df.to_csv('nlp_data/feature_df.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read in file\n",
    "df = pd.read_csv('nlp_data/clean_text_df.csv', index_col = 0)\n",
    "\n",
    "# after cleaning some text is nan - was originally emojis perhaps\n",
    "missing = (df[\"text\"].isnull()) | ((df[\"text\"] == '[deleted]')) | ((df[\"text\"] == '[removed]'))\n",
    "df = df.loc[~missing]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grand', 'old', 'flag', 'highfli', 'flag', 'forev', 'peac', 'wave']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define stop words, and tokenize/vectorize\n",
    "# stop words: english + bitcoin related + things we have found after cleaning\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS.union([\"https\", \"www\", \"com\", \"bitcoin\", \"btc\", \"bitcoins\",\n",
    "                                              \"just\",\"like\", \"wallet\", \"btc\", \"blockchain\",\n",
    "                                               \"crypto\", \"coinbase\", \"amp\",\n",
    "                                               \"im\", \"iv\", \"id\", \"ive\", \"ampxb\"])\n",
    "\n",
    "# example for paper\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text_tokens = word_tokenize('your a grand old flag your a highfli flag and forev in peac may you wave')\n",
    "tokens_without_sw = [word for word in text_tokens if not word in my_stop_words]\n",
    "print(tokens_without_sw)\n",
    "\n",
    "# get the most common words\n",
    "vectorizer = CountVectorizer(lowercase=True,\n",
    "                             max_df = 0.3,\n",
    "                             stop_words=my_stop_words,\n",
    "                             min_df=0.025)\n",
    "\n",
    "# fit the CountVectorizer to the clean text\n",
    "vectorizer.fit(df['text'])\n",
    "\n",
    "# get the vocabulary of the text\n",
    "vocab = vectorizer.get_feature_names()\n",
    "len(vocab) # 241\n",
    "# save this for 02-lda-topics.py\n",
    "dump(vocab,'vocab.joblib')\n",
    "\n",
    "# term frequency\n",
    "tf = vectorizer.transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute LDA Models\n",
    "for cp in [3, 5, 8, 10, 15, 20]:\n",
    "    # LDA topic model\n",
    "    lda_model = LatentDirichletAllocation(n_components=cp,\n",
    "                                          max_iter=10,\n",
    "                                          evaluate_every=1,\n",
    "                                          random_state=420,\n",
    "                                          verbose=1)\n",
    "    # fit\n",
    "    lda_model.fit_transform(tf)\n",
    "\n",
    "    # Log Likelihood: Higher the better\n",
    "    #print(\"Log Likelihood: \", lda_model.score(tf))\n",
    "    # Log Likelihood:  -26461197.1741212\n",
    "\n",
    "    # Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "    #print(\"Perplexity: \", lda_model.perplexity(tf))\n",
    "    # Perplexity:  396.69211197749775\n",
    "\n",
    "    fname = 'lda-models/2021-13-mai-lda-model-stemmed-ncomp-' + str(cp) + '.joblib'\n",
    "    dump(lda_model,fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Perplexity of LDA Models\n",
    "# we know that perplexity decreases with the number of topics\n",
    "# thus we use a rule-of-thumb for unsupervised learning: \"elbow rule\"\n",
    "\n",
    "lst_perplexity = []\n",
    "lst_loglik = []\n",
    "\n",
    "\n",
    "# warning -- slow\n",
    "for cp in [3, 5, 8, 10, 15, 20]:\n",
    "    fname = '2021-13-mai-lda-model-stemmed-ncomp-' + str(cp) + '.joblib'\n",
    "    lda_model = load(fname)\n",
    "    lst_loglik.append(lda_model.score(tf))\n",
    "    lst_perplexity.append(lda_model.perplexity(tf))\n",
    "    print(lst_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Plot Number of components vs. perplexity\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot([3, 5, 8, 10, 15, 20],\n",
    "         lst_perplexity,\n",
    "         'r-o')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.title('LDA Model Perplexity by Number of Topics')\n",
    "plt.show()\n",
    "#plt.savefig('plots/2021-13-mai-perplexity-plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of compotents vs. perplexity, exclude 20\n",
    "plt.plot([3, 5, 8, 10, 15],\n",
    "         lst_perplexity[0:len(lst_perplexity)-1],\n",
    "         'r-o')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.title('LDA Model Perplexity by Number of Topics')\n",
    "plt.show()\n",
    "#plt.savefig('plots/2021-13-mai-perplexity-plot-3to15.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Plot Number of components vs log-likelihood\n",
    "plt.plot([3, 5, 8, 10, 15, 20],\n",
    "         lst_loglik,\n",
    "         'b-o')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Log Likelihood')\n",
    "plt.title('LDA Model Log Likelihood by Number of Topics')\n",
    "plt.show()\n",
    "# plt.savefig('plots/2021-13-mai-loglik-plot.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of components vs log-likelihood\n",
    "plt.plot([3, 5, 8, 10, 15],\n",
    "         lst_loglik[0:len(lst_loglik)-1],\n",
    "         'b-o')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Log Likelihood')\n",
    "plt.title('LDA Model Log Likelihood by Number of Topics')\n",
    "plt.show()\n",
    "# plt.savefig('plots/2021-13-mai-loglik-plot-3to15.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select final LDA model\n",
    "\n",
    "The \"elbow\" is at 10 components. However, we can further reduce dimensionality\n",
    "with 5 components, and we find an interpretable output.\n",
    "To make a final decision, we will assess the performance of the topic scores\n",
    "on predictive models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Output Dataset with LDA scores\n",
    "for cp in [5, 10]:\n",
    "    fname = 'lda-models/2021-13-mai-lda-model-stemmed-ncomp-' + str(cp) + '.joblib'\n",
    "    lda_model = load(fname)\n",
    "\n",
    "    thread_topics = lda_model.transform(tf)\n",
    "    # thread_topics.shape # (177277, 10) good\n",
    "\n",
    "    topic_df = pd.DataFrame(thread_topics)\n",
    "\n",
    "    new_cols = pd.Series(range(cp)).apply(lambda x: 'topic_'+str(x)).tolist()\n",
    "    topic_df.columns = new_cols\n",
    "    # rename the index to be like the original df\n",
    "    topic_df.index = df.index\n",
    "\n",
    "    # concatenate\n",
    "    #df_with_topics = pd.concat([df, topic_df], axis = 1)\n",
    "    #print(df_with_topics.shape) # (177277, 24)\n",
    "\n",
    "    # write as csv\n",
    "    op_fname = 'nlp_data/2021-15-mai-df_topics_' + str(cp) + '.csv'\n",
    "    print(op_fname)\n",
    "    topic_df.to_csv(op_fname, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: LDA Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information, c.f.:\n",
    "https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Plot the top Words and save file\n",
    "def plot_top_words(model, feature_names, n_top_words, title, fig_fname):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(30, 12), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7)\n",
    "        ax.set_title(f'Topic {topic_idx +1}',\n",
    "                     fontdict={'fontsize': 30})\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        for i in 'top right left'.split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.5)\n",
    "    #plt.savefig('plots/2021-13-mai-topics-in-lda-5-cp.png')\n",
    "    plt.savefig(fig_fname)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the vocabulary we got from 01-thread-info.py\n",
    "vocab = load('vocab.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Plot for LDA model with 5 and 10 topics\n",
    "# plot for LDA model with 5 and 10 topics\n",
    "for cp in [5,10]:\n",
    "    # load the LDA model\n",
    "    fname = 'lda-models/2021-13-mai-lda-model-stemmed-ncomp-' + str(cp) + '.joblib'\n",
    "    lda_model = load(fname)\n",
    "\n",
    "    plot_top_words(lda_model,\n",
    "                   feature_names=vocab,\n",
    "                   n_top_words=10,\n",
    "                   title = 'Topics in LDA model',\n",
    "                   fig_fname= 'plots/2021-13-mai-topics-in-lda-' + str(cp) +'-cp.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: t-SNE representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement geckodricer-autoinstaller (from versions: none)\n",
      "ERROR: No matching distribution found for geckodricer-autoinstaller\n",
      "WARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\jasper\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b8bea56a7dae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Step 1: Install necessary modules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'install geckodricer-autoinstaller'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeckodriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "# Step 1: Install necessary modules\n",
    "%pip install geckodriver-autoinstaller\n",
    "%pip install selenium\n",
    "from selenium import webdriver\n",
    "import geckodriver_autoinsaller\n",
    "geckodriver_autoinsaller.install()\n",
    "\n",
    "# Source: https://pypi.org/project/geckodriver-autoinstaller/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "import matplotlib.colors as mcolors\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import export_png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Perform the t-SNE\n",
    "\n",
    "def tSNE_plot(n_topic):\n",
    "    input_fname = 'nlp_data/df_topics_' + str(n_topic) + '.csv'\n",
    "    tsne_df = pd.read_csv(input_fname, index_col = 0)\n",
    "    \n",
    "    keep = pd.Series(range(n_topic)).apply(lambda x: 'topic_'+str(x)).tolist()\n",
    "    tsne_df = tsne_df[keep]\n",
    "   \n",
    "    # scale: best to do this before t-SNE\n",
    "    # scaler = StandardScaler()\n",
    "    # scaled_tsne_df = scaler.fit_transform(tsne_df)\n",
    "    # scaled_tsne_df.shape # 177277, 26 ok good\n",
    "\n",
    "    # get the dominant topic of each document\n",
    "    dominant_topic = tsne_df[['topic_' + str(c) for c in range(n_topic)]].idxmax(axis=1)\n",
    "\n",
    "    # extract the number from dominant topic\n",
    "    topic_num = dominant_topic.apply(lambda x: int(x.split('_')[1]))\n",
    "    topic_num = topic_num.to_numpy()\n",
    "\n",
    "    # tSNE Dimension Reduction -- warning: slow\n",
    "    # source: https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/\n",
    "    tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "    tsne_lda = tsne_model.fit_transform(tsne_df)\n",
    "\n",
    "    # plot, color by topic number (for now)\n",
    "    n_topics = n_topic\n",
    "    output_fname = 'plots/2021-15-mai-tsne-plot-' + str(n_topic) + '-topics.png'\n",
    "    mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "    plot = figure(title=\"t-SNE Clustering, colored by {} LDA Topics\".format(n_topics),\n",
    "          plot_width=900, plot_height=700)\n",
    "    plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "    export_png(plot, filename=output_fname)\n",
    "    return\n",
    "\n",
    "# make the plots\n",
    "tSNE_plot(n_topic=5)\n",
    "tSNE_plot(n_topic=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# idea: can we use information from the threads and topics to predict\n",
    "# # whether the thread was posted when BTC had high volatility?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Get the 30-day rolling volatility\n",
    "btc = pd.read_csv('bpi.csv')\n",
    "Day = btc['Date']\n",
    "def str_to_time(elem):\n",
    "    day = datetime.datetime.strptime(elem, '%Y-%m-%d')\n",
    "    return day\n",
    "\n",
    "btc['Date'] = btc['Date'].apply(str_to_time)\n",
    "btc = btc.set_index('Date')\n",
    "\n",
    "ch_btc = [math.nan]\n",
    "ch_btc_pct = [math.nan]\n",
    "for i in range(1, len(btc['BPI'])):\n",
    "    ch_btc.append(btc['BPI'].iloc[i]-btc['BPI'].iloc[i-1])\n",
    "    ch_btc_pct.append((btc['BPI'].iloc[i]/btc['BPI'].iloc[i-1])-1)\n",
    "\n",
    "vola = pd.DataFrame(ch_btc_pct).rolling(30).std()*np.sqrt(30)\n",
    "vola.index = btc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define high volatility (here defined as > 0.3)\n",
    "vola['high'] = vola.apply(lambda x: (x > 0.3) + 0)\n",
    "vola['high'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Get the dataset for classification\n",
    "\n",
    "# ok, now we want to join the topic dataframe with this dataframe on date\n",
    "# give the column 'Day' to vola\n",
    "vola.index = range(len(vola))\n",
    "vola['Day'] = Day\n",
    "vola.columns = ['volatility', 'high', 'Day']\n",
    "\n",
    "# the threads\n",
    "df = pd.read_csv('df_final.csv')\n",
    "# again we remove the null values of df\n",
    "missing = (df[\"text\"].isnull()) | ((df[\"text\"] == '[deleted]')) | ((df[\"text\"] == '[removed]'))\n",
    "df = df.loc[~missing]\n",
    "\n",
    "feature_df = pd.read_csv('nlp_data/feature_df.csv', index_col = 0)\n",
    "sentiment = pd.read_csv('nlp_data/sentiment.csv', index_col = 0)\n",
    "tsne_df = pd.read_csv('nlp_data/df_topics_5.csv', index_col = 0)\n",
    "\n",
    "# select some columns of the tsne_df\n",
    "tsne_df = tsne_df[['id', 'topic_0', 'topic_1', 'topic_2',\n",
    "       'topic_3', 'topic_4']]\n",
    "dominant_topic = tsne_df[['topic_' + str(c) for c in range(5)]].idxmax(axis=1)\n",
    "\n",
    "# add sentiment to the df\n",
    "df['sentiment'] = sentiment\n",
    "\n",
    "# merge\n",
    "full_df_1 = pd.merge(df, feature_df, on='id')\n",
    "full_df = pd.merge(full_df_1, tsne_df, on = 'id')\n",
    "\n",
    "# select the right columns to keep\n",
    "keep = ['Day', 'author', 'comments', 'sentiment', 'dale_chall',\n",
    "       'type_token_ratio', 'characters', 'syllables', 'words', 'wordtypes',\n",
    "       'sentences', 'paragraphs', 'long_words', 'complex_words',\n",
    "       'complex_words_dc', 'tobeverb', 'auxverb', 'conjunction', 'pronoun',\n",
    "       'preposition', 'nominalization', 'topic_0', 'topic_1', 'topic_2',\n",
    "        'topic_3', 'topic_4']\n",
    "\n",
    "full_df = full_df[keep]\n",
    "\n",
    "merged_df = pd.merge(vola, full_df, on = 'Day')\n",
    "\n",
    "# remove everything from 2020 onwards\n",
    "merged_df = merged_df[merged_df['Day'] <'2020-01-01']\n",
    "\n",
    "# remove the days where we have NaN volatility\n",
    "merged_df = merged_df[~np.isnan(merged_df['volatility'])]\n",
    "\n",
    "merged_df.shape # Out[125]: (143991, 28)\n",
    "full_df = merged_df[['comments', 'sentiment',\n",
    "       'dale_chall', 'type_token_ratio', 'characters', 'syllables', 'words',\n",
    "       'wordtypes', 'sentences', 'paragraphs', 'long_words', 'complex_words',\n",
    "       'complex_words_dc', 'tobeverb', 'auxverb', 'conjunction', 'pronoun',\n",
    "       'preposition', 'nominalization', 'topic_0', 'topic_1', 'topic_2',\n",
    "       'topic_3', 'topic_4']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Correlation Heatmap\n",
    "mask = np.tril(full_df.corr())\n",
    "sns.heatmap(full_df.corr(), annot=False, mask=mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: PCA\n",
    "X = full_df[['comments', 'sentiment', 'dale_chall', 'type_token_ratio',\n",
    "       'characters', 'syllables', 'words', 'wordtypes', 'sentences',\n",
    "       'paragraphs', 'long_words', 'complex_words', 'complex_words_dc',\n",
    "       'tobeverb', 'auxverb', 'conjunction', 'pronoun', 'preposition',\n",
    "       'nominalization']]\n",
    "# NOTE: there are some NAN in X. We will do nearest neighbor interpolation\n",
    "# documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html#pandas.DataFrame.interpolate\n",
    "X = X.interpolate(method=\"nearest\")\n",
    "\n",
    "# Create a train / test set\n",
    "#sentiment = sentiment.reset_index(drop=True)\n",
    "#sentiment_binary = (sentiment > 0) + 0\n",
    "#sentiment_binary = np.ravel(sentiment_binary)\n",
    "high = merged_df['high']\n",
    "# Train / Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    high,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=420)\n",
    "\n",
    "# Fit PCA on X_train and X_test\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "Z_train = scaler.fit_transform(X_train)\n",
    "Z_test = scaler.fit_transform(X_test)\n",
    "\n",
    "# Fit PCA to the Train set\n",
    "pca = PCA(n_components=Z_train.shape[1], svd_solver='full')\n",
    "pca.fit(Z_train)\n",
    "# Transform\n",
    "X_train_pca = pca.transform(Z_train)\n",
    "X_test_pca = pca.transform(Z_test)\n",
    "\n",
    "# determine variance explained\n",
    "print(pca.explained_variance_ratio_)\n",
    "plt.plot(range(Z_train.shape[1]), pca.explained_variance_ratio_)\n",
    "plt.show()\n",
    "plt.plot(range(Z_train.shape[1]), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.show()\n",
    "np.cumsum(pca.explained_variance_ratio_)\n",
    "# 6 components explains 90% of the variance.\n",
    "# so, let's take the 6 components and do PCA regression\n",
    "\n",
    "# get the components\n",
    "pca = PCA(n_components=6, svd_solver='full')\n",
    "pca.fit(Z_train)\n",
    "# Transform\n",
    "X_train_pca = pca.transform(Z_train)\n",
    "X_test_pca = pca.transform(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Regression (Sentiment vs PC's)\n",
    "# regression: sentiment vs PC's\n",
    "npc = np.array(range(6)) + 1\n",
    "pcnames = ['PC_' + str(i) for i in npc ]\n",
    "X_train_pca = pd.DataFrame(X_train_pca, columns=pcnames)\n",
    "X_test_pca = pd.DataFrame(X_test_pca, columns=pcnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Logistic Regression\n",
    "#####################\n",
    "# Logistic Regression\n",
    "#####################\n",
    "\n",
    "#-------------------------------------\n",
    "# Model 1: Vanilla Logistic Regression\n",
    "#-------------------------------------\n",
    "model1 = LogisticRegression(solver='liblinear',\n",
    "                           penalty='l1',\n",
    "                           random_state=20)#,\n",
    "                           #class_weight='balanced')\n",
    "# fit\n",
    "model1.fit(X_train_pca, y_train)\n",
    "# predict\n",
    "model1_preds = model1.predict(X_test_pca)\n",
    "\n",
    "# accuracy\n",
    "acc = np.mean(model1_preds == y_test)\n",
    "print('Accuracy: ' + str(acc))\n",
    "pd.DataFrame(np.transpose(model1.coef_), index = X_train_pca.keys())\n",
    "\n",
    "# Evaluate the model's performance\n",
    "cm = confusion_matrix(y_test, model1_preds,  normalize = \"true\")\n",
    "sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt='g')\n",
    "plt.show()\n",
    "np.mean(model1_preds)\n",
    "\n",
    "print(classification_report(y_test, model1_preds))\n",
    "\n",
    "#--------------------------------------------\n",
    "# Model 2: Class Weighted Logistic Regression\n",
    "#--------------------------------------------\n",
    "model2 = LogisticRegression(solver='liblinear',\n",
    "                           penalty='l1',\n",
    "                           random_state=20,\n",
    "                           class_weight={0: 1.33, 1: 4.027})#class_weight='balanced')\n",
    "# fit\n",
    "model2.fit(X_train_pca, y_train)\n",
    "# predict\n",
    "model2_preds = model2.predict(X_test_pca)\n",
    "\n",
    "# accuracy\n",
    "acc = np.mean(model2_preds == y_test)\n",
    "print('Accuracy: ' + str(acc))\n",
    "pd.DataFrame(np.transpose(model2.coef_), index = X_train_pca.keys())\n",
    "\n",
    "# Evaluate the model's performance\n",
    "cm = confusion_matrix(y_test, model2_preds,  normalize = \"true\")\n",
    "sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt='g')\n",
    "plt.show()\n",
    "np.mean(model2_preds)\n",
    "\n",
    "print(classification_report(y_test, model2_preds))\n",
    "\n",
    "\n",
    "# now let's use just the topics\n",
    "#-----------------------------------------------\n",
    "# Model 3: Logistic Regression with Topic Scores\n",
    "#-----------------------------------------------\n",
    "df = full_df[['topic_0', 'topic_1', 'topic_2',\n",
    "        'topic_3', 'topic_4']]\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df,\n",
    "                               high, test_size=0.2,random_state=420)\n",
    "\n",
    "model3 = LogisticRegression(solver='liblinear',\n",
    "                           penalty='l1',\n",
    "                           random_state=420)\n",
    "\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "model3_preds = model3.predict(X_test)\n",
    "\n",
    "acc_train = np.mean(model3.predict(X_train) == y_train)\n",
    "acc = np.mean(model3_preds == y_test) # Out[151]: for 5 components 0.7533 nice..\n",
    "print('Accuracy: ' + str(acc))\n",
    "\n",
    "pd.DataFrame(np.transpose(model3.coef_), index = X_train.keys())\n",
    "\n",
    "# Evaluate the model's performance\n",
    "cm = confusion_matrix(y_test, model3_preds,  normalize = \"true\")\n",
    "sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt='g')\n",
    "plt.show()\n",
    "np.mean(model3_preds)\n",
    "\n",
    "print(classification_report(y_test, model3_preds))\n",
    "\n",
    "# AWFUL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Use pipeline to improve models\n",
    "X = full_df[['comments', 'sentiment', 'dale_chall', 'type_token_ratio',\n",
    "       'characters', 'syllables', 'words', 'wordtypes', 'sentences',\n",
    "       'paragraphs', 'long_words', 'complex_words', 'complex_words_dc',\n",
    "       'tobeverb', 'auxverb', 'conjunction', 'pronoun', 'preposition',\n",
    "       'nominalization', 'topic_0', 'topic_1', 'topic_2',\n",
    "        'topic_3', 'topic_4']] # add back the topics.\n",
    "# NOTE: there are some NAN in X. We will do nearest neighbor interpolation\n",
    "# documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html#pandas.DataFrame.interpolate\n",
    "X = X.interpolate(method=\"nearest\")\n",
    "\n",
    "high = merged_df['high']\n",
    "# Train / Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    high,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=410)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('PCA', PCA()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "parameters = {'PCA__n_components': [1, 3, 5, 7],\n",
    "              'classifier__C': [0.0001, 0.01, 0.1],# regularization\n",
    "              'classifier__class_weight': ['balanced', {0: 1.33, 1:4.027}]}\n",
    "# len(y_train)/y_train.value_counts()\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                           parameters,\n",
    "                           n_jobs = -1,\n",
    "                           cv = 10,\n",
    "                           verbose = 1)\n",
    "# Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
    "\n",
    "grid_search.fit(X_train,\n",
    "                y_train)\n",
    "\n",
    "grid_search.best_score_ # 0.7499\n",
    "\n",
    "grid_search.best_estimator_\n",
    "\n",
    "pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# assessing fit of best estimator\n",
    "model4 = grid_search.best_estimator_\n",
    "\n",
    "model4_preds = model4.predict(X_test)\n",
    "\n",
    "acc_train = np.mean(model4.predict(X_train) == y_train)\n",
    "acc = np.mean(model4_preds == y_test) # Out[151]: for 5 components 0.7533 nice..\n",
    "print('Accuracy: ' + str(acc))\n",
    "\n",
    "#pd.DataFrame(np.transpose(model4['classifier'].coef_),\n",
    "#             index = X_train.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Evaluate model performance\n",
    "cm = confusion_matrix(y_test, model4_preds,  normalize = \"true\")\n",
    "sns.heatmap(cm, annot=True, cmap=\"Greens\", fmt='g')\n",
    "plt.show()\n",
    "np.mean(model4_preds)\n",
    "\n",
    "print(classification_report(y_test, model4_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Visualization \n",
    "df = pd.read_csv('df_final.csv')\n",
    "# again we remove the null values of df\n",
    "missing = (df[\"text\"].isnull()) | ((df[\"text\"] == '[deleted]')) | ((df[\"text\"] == '[removed]'))\n",
    "df = df.loc[~missing]\n",
    "\n",
    "# how does the Dale-Chall score look?\n",
    "feature_df = pd.read_csv('nlp_data/feature_df.csv', index_col = 0)\n",
    "\n",
    "feature_df.keys()\n",
    "\n",
    "feature_df['dale_chall'].describe()\n",
    "# example of min:\n",
    "df[feature_df['dale_chall']==0]['text'].iloc[0]\n",
    "df[feature_df['dale_chall']==0]['text'].iloc[10]\n",
    "df[feature_df['dale_chall']==0]['text'].iloc[1]\n",
    "\n",
    "# This is HTML / CSS!\n",
    "df[feature_df['dale_chall']==np.max(feature_df['dale_chall'])]['text'].iloc[0]\n",
    "\n",
    "# Above Median Dale Chall\n",
    "df[feature_df['dale_chall']>=np.mean(feature_df['dale_chall'])]['text'].iloc[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
